{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "path ='AES/AES_corpus'\n",
    "\n",
    "def readData(path):\n",
    "    count = 0\n",
    "    datadictionary = {}\n",
    "    for i in os.walk(path):\n",
    "        for j in i[2]:\n",
    "            #print(j)\n",
    "            file = open(path+'/'+j, encoding=\"utf8\")\n",
    "            data=json.loads(file.read())\n",
    "            if 'aes_sch_body_t' in data:\n",
    "                datadictionary.update({count:data['aes_sch_body_t']})\n",
    "                count += 1\n",
    "    return datadictionary\n",
    "\n",
    "DD = readData(path)\n",
    "dataset = pd.DataFrame.from_dict(DD, orient='index', columns=['Description'])\n",
    "\n",
    "def vocab_tfidf(corpus, ngram):\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (ngram,ngram))\n",
    "    TF = vectorizer.fit(corpus)\n",
    "    return TF.vocabulary_\n",
    "\n",
    "X = dataset.Description\n",
    "\n",
    "TF3 = vocab_tfidf(X,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words=\"english\")\n",
    "vec.fit(X)\n",
    "features = vec.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = MiniBatchKMeans(n_clusters= 5 , random_state=0)\n",
    "clust  = cls.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, label in enumerate(kmeans.labels_):\n",
    "        clustering[label].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clustering[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering K means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/Notebooks/Sahil/Corpus Analysis Technology'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import walk\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "path ='AES/AES_corpus'\n",
    "\n",
    "def readData(path):\n",
    "    count = 0\n",
    "    datadictionary = {}\n",
    "    for i in os.walk(path):\n",
    "        for j in i[2]:\n",
    "            #print(j)\n",
    "            file = open(path+'/'+j, encoding=\"utf8\")\n",
    "            data=json.loads(file.read())\n",
    "            if 'aes_sch_body_t' in data:\n",
    "                datadictionary.update({count:data['aes_sch_body_t']})\n",
    "                count += 1\n",
    "    return datadictionary\n",
    "\n",
    "DD = readData(path)\n",
    "dataset = pd.DataFrame.from_dict(DD, orient='index', columns=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wws, what we sell, mmp, manage my page, contac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Modernization, Mainframe, Applications, Develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium, Flanders, Flemish, Vlaamse Overheid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft, gtm, agreement, digital, transforma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSVx Sales Presentation Infrastructure as Code...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description\n",
       "0  wws, what we sell, mmp, manage my page, contac...\n",
       "1  Modernization, Mainframe, Applications, Develo...\n",
       "2  Belgium, Flanders, Flemish, Vlaamse Overheid, ...\n",
       "3  microsoft, gtm, agreement, digital, transforma...\n",
       "4  MSVx Sales Presentation Infrastructure as Code..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (3,3))\n",
    "TF = vectorizer.fit(X)\n",
    "features = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 3\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', n_init=1)\n",
    "model.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = TF.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15731875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " of page powered\n",
      " wordpress com vip\n",
      " by wordpress com\n",
      " page powered by\n",
      " powered by wordpress\n",
      " to top of\n",
      " return to top\n",
      " top of page\n",
      " name email website\n",
      " comment data is\n",
      " reduce spam learn\n",
      " your comment data\n",
      " to reduce spam\n",
      " how your comment\n",
      " email website this\n",
      " uses akismet to\n",
      " spam learn how\n",
      " website this site\n",
      " processed return to\n",
      " akismet to reduce\n",
      " is processed return\n",
      " site uses akismet\n",
      " this site uses\n",
      " learn how your\n",
      " data is processed\n",
      " procter and gamble\n",
      " dxc blogs the\n",
      " artificial intelligence ai\n",
      " one of the\n",
      " digital from to\n",
      "Cluster 1:\n",
      " look for evidence\n",
      " document revision history\n",
      " and text revised\n",
      " for evidence that\n",
      " indicated in the\n",
      " information in the\n",
      " the configuration management\n",
      " the document revision\n",
      " criteria id verification\n",
      " regular revision history\n",
      " arial regular revision\n",
      " tips relative importance\n",
      " relative importance reference\n",
      " id verification criteria\n",
      " criteria tips relative\n",
      " importance reference id\n",
      " apr 2017 edge\n",
      " the templates template\n",
      " included legal statement\n",
      " copyright legal statement\n",
      " statement to reflect\n",
      " revised note based\n",
      " and copyright legal\n",
      " verification criteria tips\n",
      " reflect dxc technology\n",
      " templates template revision\n",
      " revised apr 2017\n",
      " technology logo and\n",
      " team rsa included\n",
      " rsa included legal\n",
      "Cluster 2:\n",
      " proprietary and confidential\n",
      " dxc proprietary and\n",
      " 2018 dxc proprietary\n",
      " 2019 dxc proprietary\n",
      " 2017 dxc proprietary\n",
      " www dxc technology\n",
      " end to end\n",
      " of covid 19\n",
      " as well as\n",
      " one of the\n",
      " dxc technology company\n",
      " all rights reserved\n",
      " for more information\n",
      " ask to see\n",
      " details apr 2020\n",
      " internal use only\n",
      " be able to\n",
      " name please enter\n",
      " apply recommend friend\n",
      " yes you can\n",
      " on transforming business\n",
      " company all rights\n",
      " some of the\n",
      " falls church va\n",
      " technology company all\n",
      " the age of\n",
      " more information visit\n",
      " in the age\n",
      " in order to\n",
      " need tech global\n"
     ]
    }
   ],
   "source": [
    "## Only Printing\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :30]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " the\n",
      " look for\n",
      " look\n",
      " and\n",
      " for\n",
      " test\n",
      " to\n",
      " been\n",
      " for evidence\n",
      " look for evidence\n",
      " evidence\n",
      " plan\n",
      " of\n",
      " evidence that\n",
      " for evidence that\n",
      " testing\n",
      " project\n",
      " that\n",
      " change\n",
      " criteria\n",
      " documented\n",
      " or\n",
      " are\n",
      " in\n",
      " have\n",
      " document\n",
      " has\n",
      " the project\n",
      " been created\n",
      " data\n",
      " review\n",
      " revision history\n",
      " revision\n",
      " verify\n",
      " requirements\n",
      " management\n",
      " created\n",
      " in the\n",
      " evidence that the\n",
      " history\n",
      " management plan\n",
      " schedule\n",
      " release\n",
      " identified\n",
      " for the\n",
      " is\n",
      " request\n",
      " configuration\n",
      " be\n",
      " that the\n",
      " configuration management\n",
      " were\n",
      " work\n",
      " test data\n",
      " was\n",
      " by\n",
      " being\n",
      " verification\n",
      " reviewed\n",
      " design\n",
      " test cases\n",
      " defined\n",
      " work product\n",
      " of the\n",
      " service\n",
      " change request\n",
      " program\n",
      " approved\n",
      " changes\n",
      " approval\n",
      " the testing\n",
      " determine\n",
      " appropriate\n",
      " ask to see\n",
      " if\n",
      " statement\n",
      " level\n",
      " as\n",
      " application\n",
      " has the\n",
      " iteration\n",
      " ask to\n",
      " ensure\n",
      " activities\n",
      " test conditions\n",
      " to the\n",
      " verification criteria\n",
      " amdsa\n",
      " actions\n",
      " test plan\n",
      " conducted\n",
      " amchm\n",
      " amsdm\n",
      " legal statement\n",
      " and iso\n",
      " status\n",
      " document revision history\n",
      " document revision\n",
      " by section\n",
      " and text revised\n",
      "Cluster 1:\n",
      " the\n",
      " and\n",
      " to\n",
      " in\n",
      " of\n",
      " covid\n",
      " covid 19\n",
      " of covid 19\n",
      " of covid\n",
      " please enter\n",
      " you\n",
      " please\n",
      " enter\n",
      " is\n",
      " for\n",
      " can\n",
      " name please enter\n",
      " name please\n",
      " it\n",
      " remote\n",
      " on transforming business\n",
      " yes you can\n",
      " that\n",
      " 19\n",
      " transforming business\n",
      " newsletter\n",
      " on transforming\n",
      " yes you\n",
      " on\n",
      " digital\n",
      " in the\n",
      " business\n",
      " with\n",
      " technology\n",
      " tech global reach\n",
      " we need tech\n",
      " need tech global\n",
      " age of covid\n",
      " covid 19 we\n",
      " 19 we need\n",
      " tech global\n",
      " need tech\n",
      " 2020\n",
      " 19 we\n",
      " in the age\n",
      " peter\n",
      " the age of\n",
      " the age\n",
      " data\n",
      " age of\n",
      " global reach\n",
      " monthly\n",
      " as\n",
      " we\n",
      " by\n",
      " age\n",
      " yes\n",
      " midst of covid\n",
      " make remote working\n",
      " remote working work\n",
      " working work in\n",
      " working work\n",
      " make remote\n",
      " remote working\n",
      " remote workforce\n",
      " the midst of\n",
      " in the midst\n",
      " midst of\n",
      " the midst\n",
      " midst\n",
      " your\n",
      " me\n",
      " you can\n",
      " transforming\n",
      " are\n",
      " work in the\n",
      " need\n",
      " tech\n",
      " we need\n",
      " ai\n",
      " more\n",
      " be\n",
      " reach\n",
      " make\n",
      " dxc technology\n",
      " work in\n",
      " email\n",
      " how\n",
      " in september\n",
      " emails yes\n",
      " emails yes you\n",
      " select language\n",
      " me emails yes\n",
      " language preference in\n",
      " send me emails\n",
      " enter last\n",
      " enter last name\n",
      " me emails\n",
      " enter name please\n",
      " select language preference\n",
      "Cluster 2:\n",
      " the\n",
      " revision history\n",
      " revision\n",
      " and\n",
      " history\n",
      " document\n",
      " criteria\n",
      " change\n",
      " change request\n",
      " and iso\n",
      " legal statement\n",
      " document revision history\n",
      " document revision\n",
      " verification criteria\n",
      " by section\n",
      " and text revised\n",
      " text revised\n",
      " modified by\n",
      " and text\n",
      " to\n",
      " configuration management\n",
      " revised\n",
      " verification\n",
      " copyright\n",
      " iso\n",
      " modified\n",
      " request\n",
      " template\n",
      " statement\n",
      " by\n",
      " text\n",
      " id\n",
      " section\n",
      " legal\n",
      " configuration\n",
      " version\n",
      " been\n",
      " look for\n",
      " 2017\n",
      " date\n",
      " dxc technology\n",
      " for\n",
      " dxc\n",
      " management\n",
      " in\n",
      " look\n",
      " reviewed\n",
      " in the\n",
      " of\n",
      " approval\n",
      " approved\n",
      " project\n",
      " from\n",
      " captured\n",
      " relative importance\n",
      " the document revision\n",
      " the configuration management\n",
      " apr 2017 edge\n",
      " reflect dxc technology\n",
      " revised note based\n",
      " statement to\n",
      " 2017 edge change\n",
      " text revised note\n",
      " copyright legal\n",
      " revised apr 2017\n",
      " templates template revision\n",
      " included legal statement\n",
      " rsa included legal\n",
      " technology logo and\n",
      " statement to reflect\n",
      " copyright legal statement\n",
      " the templates template\n",
      " rsa included\n",
      " and copyright legal\n",
      " team rsa included\n",
      " tips relative importance\n",
      " id verification criteria\n",
      " criteria id verification\n",
      " regular revision history\n",
      " importance reference\n",
      " relative importance reference\n",
      " tips relative\n",
      " arial regular revision\n",
      " importance reference id\n",
      " criteria tips relative\n",
      " revised note\n",
      " included legal\n",
      " legal statement to\n",
      " regular revision\n",
      " verification criteria tips\n",
      " criteria tips\n",
      " 2017 edge\n",
      " revised apr\n",
      " text revised apr\n",
      " dxc technology logo\n",
      " reference id notes\n",
      " id notes\n",
      " lead and iso\n",
      " perspective is indicated\n",
      " audit perspective is\n",
      "Cluster 3:\n",
      " the\n",
      " and\n",
      " to\n",
      " of\n",
      " in\n",
      " that\n",
      " for\n",
      " is\n",
      " you\n",
      " we\n",
      " it\n",
      " dxc\n",
      " with\n",
      " on\n",
      " as\n",
      " this\n",
      " are\n",
      " services\n",
      " digital\n",
      " data\n",
      " business\n",
      " be\n",
      " can\n",
      " so\n",
      " your\n",
      " by\n",
      " cloud\n",
      " or\n",
      " have\n",
      " our\n",
      " of the\n",
      " service\n",
      " will\n",
      " management\n",
      " from\n",
      " what\n",
      " technology\n",
      " security\n",
      " more\n",
      " an\n",
      " they\n",
      " new\n",
      " in the\n",
      " their\n",
      " at\n",
      " customer\n",
      " all\n",
      " but\n",
      " process\n",
      " how\n",
      " not\n",
      " re\n",
      " com\n",
      " 2018\n",
      " client\n",
      " time\n",
      " about\n",
      " solution\n",
      " there\n",
      " has\n",
      " luxoft\n",
      " confidential\n",
      " platform\n",
      " support\n",
      " if\n",
      " do\n",
      " to the\n",
      " transformation\n",
      " one\n",
      " enterprise\n",
      " proprietary\n",
      " um\n",
      " proprietary and\n",
      " proprietary and confidential\n",
      " and confidential\n",
      " industry\n",
      " information\n",
      " use\n",
      " analytics\n",
      " know\n",
      " solutions\n",
      " applications\n",
      " was\n",
      " 2019\n",
      " experience\n",
      " global\n",
      " which\n",
      " dxc proprietary\n",
      " dxc proprietary and\n",
      " application\n",
      " on the\n",
      " system\n",
      " into\n",
      " clients\n",
      " need\n",
      " also\n",
      " through\n",
      " end\n",
      " automation\n",
      " these\n",
      "Cluster 4:\n",
      " csc\n",
      " and\n",
      " the\n",
      " of\n",
      " to\n",
      " in\n",
      " services\n",
      " for\n",
      " church va\n",
      " falls church\n",
      " falls church va\n",
      " church\n",
      " va\n",
      " falls\n",
      " the company\n",
      " technology\n",
      " business\n",
      " about csc\n",
      " csc has\n",
      " solutions\n",
      " solutions and services\n",
      " company\n",
      " csc is\n",
      " nyse csc\n",
      " www dxc technology\n",
      " csc nyse csc\n",
      " csc nyse\n",
      " www dxc\n",
      " information\n",
      " approximately\n",
      " www\n",
      " for more information\n",
      " global\n",
      " leader in\n",
      " sector\n",
      " billion\n",
      " is\n",
      " visit\n",
      " north american public\n",
      " american public\n",
      " more information\n",
      " american public sector\n",
      " billion for\n",
      " billion for the\n",
      " 2010\n",
      " revenue of\n",
      " information visit the\n",
      " global leader\n",
      " at www\n",
      " solutions and\n",
      " visit the company\n",
      " is global leader\n",
      " news release\n",
      " nyse\n",
      " at www dxc\n",
      " north american\n",
      " 12 months ended\n",
      " csc has approximately\n",
      " for the 12\n",
      " the 12 months\n",
      " reported revenue of\n",
      " employees and reported\n",
      " reported revenue\n",
      " ended\n",
      " and services\n",
      " and reported revenue\n",
      " as\n",
      " months ended\n",
      " more information visit\n",
      " has approximately\n",
      " information visit\n",
      " leader\n",
      " for more\n",
      " 000 employees and\n",
      " the 12\n",
      " information technology\n",
      " visit the\n",
      " global leader in\n",
      " will\n",
      " and reported\n",
      " has\n",
      " csc csc\n",
      " president\n",
      " is global\n",
      " about csc csc\n",
      " american\n",
      " providing technology enabled\n",
      " in falls church\n",
      " va csc\n",
      " in falls\n",
      " va csc has\n",
      " headquartered in falls\n",
      " church va csc\n",
      " in providing technology\n",
      " csc is global\n",
      " leader in providing\n",
      " providing technology\n",
      " at\n",
      " 000 employees\n",
      " technology enabled\n"
     ]
    }
   ],
   "source": [
    "savefile = []\n",
    "for i in range(true_k):\n",
    "    #print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :100]:\n",
    "        #print(' %s' % terms[ind])\n",
    "        savefile.append(terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cluster1000.txt\", \"w\") as output:\n",
    "    output.write(str(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Cluster100.pkl', 'wb') as f:\n",
    "    pickle.dump(terms, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 to 3 Grams Approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1,3))\n",
    "vectorizer = vectorizer.fit(X)\n",
    "features = vectorizer.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
