{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPos(SearchSentence):\n",
    "    \"\"\" Find the different tags to identify POS of search Sentence using Spacy\n",
    "    --- parameters -- \n",
    "    SearchSentence is the input Search query from user\n",
    "    \"\"\"\n",
    "    datadictionary = {}\n",
    "    for token in nlp(SearchSentence):\n",
    "        datadictionary.update({token.text : [token.lemma_, token.pos_, token.tag_, token.dep_, token.ent_type_, token.shape_, \n",
    "                                             token.is_alpha, token.is_stop, token.head.text, token.head.pos_, [child for child in token.children]]})\n",
    "    return datadictionary\n",
    "\n",
    "## Transform the dictionary into DataFrame\n",
    "def Trans_to_dataframe(datadictionary):\n",
    "    \"\"\" Convert the Dictionary into DataFrame \n",
    "    parameters\n",
    "    --- datadictionary is a dictionary having different token entities\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.DataFrame(datadictionary).transpose()\n",
    "    df.columns=['Lemma', 'Pos', 'Tag', 'Dep', 'Ent','Shape', 'ISAlpha', 'Is_StopWord', 'Head_Text', 'Head_Pos','Children']\n",
    "    return df\n",
    "\n",
    "def RunSearch(SearchSentence):\n",
    "    \"\"\" Nested Function which will run TWO different functions and return Data Frame\n",
    "        This Data Frame will be iterated and Main Concept and Sub Concept will be identified \n",
    "    \"\"\"\n",
    "    dicta = FindPos(SearchSentence)\n",
    "    DF = Trans_to_dataframe(dicta)\n",
    "    return(DF)\n",
    "\n",
    "def NounPhrasing(SearchSentence):\n",
    "    \"\"\" Use Spacy Noun Chunking to identify Noun Phrases and keywords\"\"\"\n",
    "    \n",
    "    NounPhrasing, keyword = [], []\n",
    "    D = FindPos(SearchSentence)\n",
    "    odd_List = ['WP', 'WRB', 'PRP'] # Avoid Which/What to be identified as Concepts\n",
    "    doc = nlp(SearchSentence)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if len(chunk.text.split(' ')) == 1:\n",
    "            if D[chunk.text][2] not in odd_List:\n",
    "                NounPhrasing.append(chunk.text)\n",
    "                keyword.append(chunk.root.text)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            NounPhrasing.append(chunk.text)\n",
    "            keyword.append(chunk.root.text)\n",
    "        \n",
    "\n",
    "        #print(chunk.text, chunk.label_)\n",
    "    \n",
    "    return NounPhrasing, keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Machine learning is a advanced application science\"\n",
    "#word = \"India won ICC Wordcup 2011\"\n",
    "#word = \"Learn Machine Learning and Data Science from good Natural Langauge Programming eBooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'ICC Wordcup']\n"
     ]
    }
   ],
   "source": [
    "NP,Key = NounPhrasing(word)\n",
    "print(NP)\n",
    "#print(Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
